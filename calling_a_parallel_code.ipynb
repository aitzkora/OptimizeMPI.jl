{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<H1> Calling a parallel simulation code from Julia</H1>\n",
    "<figure>\n",
    "<img src=\"figures/desman.jpg\" width=\"300\" alt=\"picture of a Galemys pyrenaicus\"/>\n",
    "<figcaption> <it> Galemys pyrenaicus</it> , a mammal endemic from the Pyrenees, where the author lives\n",
    "</figcaption\n",
    "</figure>\n",
    "    <H4> Marc Fuentes, INRIA </H4>\n",
    "    <H5> code and notebook available at http://github.com/aitzkora/OptimizeMPI.jl\n",
    "</center>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rationale\n",
    " \n",
    "Imagine you are a Ph.D student and use every a parallel software for simulating some physical process \n",
    "relative to your research work; For some reason, you need to optimize some \n",
    "physical parameters : In other words, you have to solve an *inverse problem*, whereas \n",
    "running your simulation is generally called *direct problem*. \n",
    "Good optimization methods are numerous, but implementing state-of-the-art methods in a low-level \n",
    "language such as Fortran, C or C++ is not straightforward. In this poster, we want to present \n",
    "some recipes (technical and numerical), to do that with \"Julia\". The knowledge level remains basic\n",
    "in a perspective to be used as a tutorial . Our hypotheses are the following : \n",
    "\n",
    " - distributed memory paradigm for parallelism (i.e. MPI) \n",
    " - direct problem is Fortran or C.\n",
    " - For optimization methods needing a gradient, implementing gradient computation method will be\n",
    " done in the low level language.\n",
    "\n",
    "To sum up with a small sketch it corresponds to \n",
    "<figure>\n",
    "<img src=\"figures/rational_call.svg\" width=\"400\"/>\n",
    "</figure> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## technical tools\n",
    "\n",
    "To manage to implement our optimization process, we need mainly of two ingredients\n",
    "1. calling a piece of external code \n",
    "2. running julia scripts in a MPI environment \n",
    "\n",
    "Let's go : \n",
    "\n",
    "### calling Fortran or C code\n",
    "\n",
    "- to call a external piece of code,  we will use the *Julia* statement `ccall`. As documented\n",
    "[here](https://docs.julialang.org/en/v1/base/c/) or [there](https://craftofcoding.wordpress.com/2017/02/08/calling-c-from-julia-i-simple-arrays/), the syntax is the following\n",
    "\n",
    "```julia\n",
    "ccall((:funcName, library), returnType, (argType1, argType2, ...), (argVal1, argVal2, ...))\n",
    "ccall(funcPtr, returnType, (argType1, argType2, ...), (argVal1, argVal2, ...))\n",
    "```\n",
    "\n",
    "where `function_name` is the mangled name of the C function in the shared library library. If you do not know\n",
    "what is mangling, take a look at [there](https://en.wikipedia.org/wiki/Name_mangling) : Roughly languages like \n",
    "Fortran (due to its case insensitivity) or C++ (in which the same function name could have several \n",
    "different signatures), must encode their function names when they interoperate with C.\n",
    "\n",
    "#### Remarks \n",
    "- `library` is only _formally_ a string :\n",
    "- you could use `\"./mylib.so\"`   \n",
    "- but ⚠ you **could not** use `string(pwd(),\"/mylib.so\")` ⚠ \n",
    "- to use a library which is not in `.`, add the path to `LD_LIBRARY_PATH` before launching \n",
    "**Julia** (Just tested on Linux, adapt the rule for MacOS with `DYLD_LIBRARY_PATH`)\n",
    "- using `dlopen` and `dlsym` one could directly use the function pointer call\n",
    "\n",
    "To start, we could do a small C example, with a function adding 2 to its argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = 14\n"
     ]
    }
   ],
   "source": [
    "io = open(\"/tmp/skel.c\",\"w\")\n",
    "write(io, \"int addTwo(int x) { return x+2; }\")\n",
    "close(io)\n",
    "run(`gcc -o addTwo.so --shared /tmp/skel.c`);\n",
    "w = ccall((:addTwo, \"./addTwo.so\"), Int32, (Int32,), 12)\n",
    "run(`rm addTwo.so /tmp/skel.c`)\n",
    "println(\"w = $w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example deserves some explanations: \n",
    "1. to build a *shared* library we add on the gcc compiler command the flag `--shared`. This is evidently,\n",
    "compiler dependant. If you use Intel, NAG or Microsoft, it could be different. To enforce more portability,\n",
    "in the sequel, we will use **CMake** as an utility to generate Makefiles and doing the compilation. To\n",
    "do that, with CMake, one could write\n",
    "```cmake\n",
    "add_library(addTwo SHARED /tmp/skel.c)\n",
    "```\n",
    "2. One big difference between Fortran and C, is the default argument pass method ; In C, it is by-value,\n",
    "so a function like `addTwo` cannot modify its arguments. To do that, you need to use pointers and furnish\n",
    "a Julia **reference** to `ccall`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "io = open(\"/tmp/skel2.c\",\"w\")\n",
    "write(io, \"void addTwoToItsArg(int  * x) { *x= *x+2; }\")\n",
    "close(io)\n",
    "run(`gcc -o addTwoToItsArg.so --shared /tmp/skel2.c`);\n",
    "z = Ref{Int32}(12) # note the reference here\n",
    "w = ccall((:addTwoToItsArg, \"./addTwoToItsArg.so\"), Cvoid, (Ref{Int32},), z)\n",
    "run(`rm addTwoItsArg.so /tmp/skel2.c`)\n",
    "println(\"z = \",z[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. To do the same in Fortran, we can use the following code\n",
    "\n",
    "```fortran\n",
    "module example\n",
    "  use iso_c_binding\n",
    "contains\n",
    "  subroutine addTwoF(x) bind(C, name =\"addTwoF\")\n",
    "    integer(c_int), intent (inout) :: x\n",
    "    x = x + 2\n",
    "  end subroutine \n",
    "end module\n",
    "```\n",
    "\n",
    "In this example, we used the statement bind to attach a C name to our Fortran function. It will override\n",
    "the mangled name, when we will use `ccall`. To enforce compatibility, Fortran 90 has some \n",
    "C compatibles types , such as  `real(c_double)`, `integer(c_int)` defined in the module `iso_c_binding`.\n",
    "The `intent(inout)` does not change how the argument is passed (by reference), it is just a information\n",
    "to enable the compiler to do more checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = 14\n"
     ]
    }
   ],
   "source": [
    "run(`gfortran -o addTwoF.so --shared ./examples/addTwoF.f90`);\n",
    "z = Ref{Int32}(12) # ✏️ VERY IMPORTANT ✏️\n",
    "w = ccall((:addTwoF, \"./addTwoF.so\"), Cvoid, (Ref{Int32},), z)\n",
    "run(`rm addTwoF.so`)\n",
    "println(\"z = \",z[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. To end with external code calling, we have to speak about arrays : Julia arrays can be convert \n",
    "to pointers without any problem, when using `ccall` As an example, \n",
    "```C\n",
    "void changeArray(int n, double * x) { if (n > 1) x[0] += 3 ; }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = [4.0, 2.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "run(`gcc -o changeArray.so --shared examples/changeArray.c`);\n",
    "a = [1:3.;]\n",
    "w = ccall((:changeArray, \"./changeArray.so\"), Cvoid, (Int32, Ptr{Float64},), size(a,1), a)\n",
    "run(`rm changeArray.so`)\n",
    "println(\"a = $a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Interacting with MPI\n",
    "\n",
    "Interacting with MPI, is not so hard, thanks to the good job done by authors of `MPI.jl` and \n",
    "`MPIClusterManagers` packages. Perhaps, before to build those packages, you need to select \n",
    "the good implementation on your system used by julia setting up some environment variables\n",
    "in your `startup.jl` file :\n",
    "```julia\n",
    "ENV[\"JULIA_MPI_C_LIBRARIES\"] = \"-L/usr/lib/openmpi/ -lmpi\"\n",
    "ENV[\"JULIA_MPI_Fortran_INCLUDE_PATH\"] = \"-I/usr/include\"\n",
    "ENV[\"JULIA_MPI_PATH\"] = \"/usr/\"\n",
    "```\n",
    "Using `MPI.jl`, the following \"hello world\" program\n",
    "```julia\n",
    "using MPI\n",
    "MPI.Init()\n",
    "println(\"Hi from $(MPI.Comm_rank(MPI.COMM_WORLD))!\")\n",
    "flush(stdout)\n",
    "```\n",
    "\n",
    "could be run directly from shell : the mpi runner calls explicitly Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi from 0!\n",
      "Hi from 1!\n"
     ]
    }
   ],
   "source": [
    "run(`mpirun -np 2 julia examples/hello_world.jl`);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Doing so, since `mpirun` calls julia, the julia code, is JIT-compiled before to execute each time we run \n",
    "the script ; Furthermore, we must run the code out of the Julia REPL, which is not very \n",
    "convenient for doing some experiments. To avoid\n",
    "that, we will use the `MPIClusterManagers` package's macro `@mpi_do`\n",
    "\n",
    "For example, one could run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added procs [1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "using MPIClusterManagers, Distributed\n",
    "manager = MPIManager(np=4)\n",
    "addprocs(manager)\n",
    "println(\"Added procs $(procs())\")\n",
    "@everywhere import MPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "and re-run several times the following block without restarting julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 2:\ts=5050.0\n"
     ]
    }
   ],
   "source": [
    "@mpi_do manager begin \n",
    "    comm = MPI.COMM_WORLD;p = MPI.Comm_size(comm);r = MPI.Comm_rank(comm)\n",
    "    s_loc=sum(1+r* 100/p:100/p * (r+1)) \n",
    "    s=MPI.Allreduce(s_loc, +, comm)\n",
    "    println(\"s=$s\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Unfortunately, the present version of MPIClusterManagers does not have an `@mpi_fetchcall` macro\n",
    "to retrieve the result of the computation on the master (which is not part of the MPI Cluster).\n",
    "Now we could look at the numerical part of this presentation\n",
    "\n",
    "### Distributed Minimization\n",
    "\n",
    "## preliminary remark\n",
    "Formally, we want to solve a problem like\n",
    "\n",
    "$$ \\arg_{x_1,\\cdots,x_p} \\min f(x_1,\\cdots,x_p) \\mbox { where } x_i \\in \\mathbb{R}^{n_i}$$\n",
    "\n",
    "the main function $f$ is assumed decomposable, i.e, we could write as a max or a sum of functions defined\n",
    "on each  $\\mathbb{R}^{n_i}$, for instance\n",
    "\n",
    "$$ f(x_1,\\cdots,x_p) = \\sum_{i=1}^p f_i(x_i)$$\n",
    "\n",
    "here we plan to use, the package `Optim` to solve our optimization problem. In almost all optimization \n",
    "methods, you have a **linesearch** step, which is responsible to find the step length $\\alpha_i^k$ to\n",
    "do in the current descent direction. Since the computation of $f$ is distributed, each algorithm, \n",
    "has its proper version of the current step. Fortunately, the linesearch uses only the value \n",
    "function, which it is the same on each process, so the `p` values of $\\alpha_i^k$ will be the same. We must\n",
    "keep this in mind, if we plan to use an algorithm where a random strategy would be used, because it would completely destroy the method.\n",
    "\n",
    "## A dummy example : the squared $L_2$ norm\n",
    "\n",
    " Suppose we want to minimize  $f(x) = \\frac{1}{2}\\|x-c\\|^2 $ where $c$ is a constant vector. The solution\n",
    " is trivially equal to $c$. We also remark that if we cut $\\mathbb{R}^n$ into some chunks, \n",
    " the $f$ function is clearly decomposable and each $f_i$ is just $f_i(x_i) = \\frac{1}{2}\\|x_i - c_i\\|^2$ where\n",
    " $c_i$ has the chunk components of $c$. Even if this case, we do not need a gradient to find the solution,\n",
    " one can computes very easily seeing that\n",
    " $$\\nabla f(x) = \\bigoplus_{i=1}^p \\nabla f_i(x_i) = \\bigoplus_{i=1}^p (x_i - c_i) $$.\n",
    " For those who are not familiar with a gradient, it is roughly like a derivative, but with multiple \n",
    " dimensions . \n",
    "\n",
    " Since this example is very dumb, we will permit ourselves, to build the partition of the \"big\" vector \n",
    " $x$, in the julia code and we will leave to the low-level code the part computing $f_i$.\n",
    " Thus, a `partition function` computes the chunk sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "function partition(n::Integer, p::Integer)\n",
    " r = n % p\n",
    " m = ceil(Integer, n / p)\n",
    " part = fill( m, p )\n",
    " part[ (r+1) * (r> 0) + (p+1) * (r==0): p ] .= m - 1\n",
    " return part\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    " dividing the global size in `p` sizes. We could gather the chunks on the 0 process with a `MPI.Gatherv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "x_glob = MPI.Gatherv(x_min,Cint[i for i in partition(n,p)] , 0, comm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The low-level part, is simply a computation of the local squared norm and with `MPI_ALLREDUCE`\n",
    " we shared the global sum among all processes. \n",
    "```fortran\n",
    "subroutine compute_error(n, x, c, f, df) bind(C, name=\"compute_error\")\n",
    "(...)\n",
    "  f = 0.d0\n",
    "  ! computing objective\n",
    "  f_loc = 0.5d0 * sum( (x - c)**2 )\n",
    "  call MPI_ALLREDUCE( f_loc, f, 1, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD, ierr )\n",
    "  ! computing gradient\n",
    "  df = x - c\n",
    "end subroutine compute_error\n",
    "```\n",
    " Now, we it remains to write the interface using `ccall`\n",
    " ```julia\n",
    " function simu!(n::Integer, x::Array{Float64,1}, df::Array{Float64,1})\n",
    "   f = Ref{Float64}(0.)\n",
    "   c = cos.(1:n)[slice[1]:slice[2]]\n",
    "   ccall((:compute_error, \"./libpar_error.so\"), \n",
    "   Cvoid, (Ref{Int32}, Ptr{Float64}, Ptr{Float64}, Ref{Float64}, Ptr{Float64}), size(x, 1), x, c, f, df)\n",
    "   return f[]\n",
    " end\n",
    " ```\n",
    " For simplicity, we choose $c_i = \\cos(i)$ and the slices are shared as a global variable (very bad!)\n",
    "\n",
    " We can now choose our favorite minimization algorithm : Most of people likes Nelder-Mead algorithm\n",
    " because it does not require gradient, but please do not use it,  proofs of convergence towards\n",
    " non-stationary points exist in the literature [Torczon](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.48.9967) \n",
    " or [McKinnon](https://www.researchgate.net/publication/2763859_Convergence_of_the_Nelder-Mead_simplex_method_to_a_non-stationary_point). Since we have a gradient at our disposal, why not choose a \"1.5\" order \n",
    " method like `LBFGS` ?\n",
    " ```julia\n",
    "res = optimize(cost, grad!, x_loc, LBFGS(), Optim.Options(... ))\n",
    " ```\n",
    " where `cost` and `grad!` are marginalized from `simu`\n",
    " ```julia\n",
    "cost = x -> simu!(n, x, df_dummy)\n",
    "grad! = (g,x)-> simu!(n,x,g)\n",
    "```  \n",
    " Note, doing that is costly, because we compute a gradient even if we just need $f$. We will see, in the\n",
    " next example that we must be able to compute $f$ without computing $\\nabla f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added procs [1, 2, 3, 4, 5]\n",
      "      From worker 2:\tf(x₀) = 24.86580624111881, |∇f(x₀)| = 7.05206441279698\n",
      "      From worker 2:\t|sol - cos(1:100)| = 0.0\n"
     ]
    }
   ],
   "source": [
    "cd(\"squared_norm\"); include(\"cluster_optim.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A less dummy example : controlling the 2D heat equation\n",
    "\n",
    " We will now consider a more realistic problem : it remains a toy problem (just 1600 loc), but to solve\n",
    " it, we will need of a classical tool for time dependent problems : the adjoint method.\n",
    " Before to explain this point, let us describe the problem\n",
    "\n",
    " We will heat a square, just applying from the beginning to the end of the simulation the same values \n",
    " on the boundary $\\Gamma$ of the square. It is our control ; we want obtain for $t=t_{final}$ some values inside \n",
    " the square as close as possible to a target function. \n",
    " In a continuous world, we want to solve\n",
    " \\begin{eqnarray}\n",
    "   \\min_p && \\int_{[0,1]^2} (u(x,t_{final}) - u_{target}(x))^2 \\, dx \\\\\n",
    "   \\mbox { such that }     && \\frac{\\partial u}{\\partial t} (x,t) = \\Delta u(x,t) \\forall (x,t) \\in [0,1]^2 \\times [0,t_{final}] \\\\ \n",
    "    && u(x,t) = p(x)  \\forall  (x,t) \\in \\Gamma \\times [0,t_{final}]\n",
    "   \\end{eqnarray}\n",
    "\n",
    "  We discretize this system, using finite differente scheme for space and Euler formula for time, and obtain\n",
    " \\begin{eqnarray}\n",
    "   \\min_p &&  \\|U^n- U^{target}\\|^2_{inside}  \\\\\n",
    "   \\mbox { such that }     && U^{n+1} = F(U^n,p) = U^n - \\frac{\\delta t}{h^2} \\cdot K2D(U^n,p) \\\\\n",
    "                           && U^0 = 0. \n",
    "   \\end{eqnarray}\n",
    "\n",
    "   where $K2D$ is the heat kernel with $p$ on the boundary. For those who do not like these formulae,\n",
    "   just remember that we have a recursive sequence of matrices, and controlling boundary matrix \n",
    "   terms, we want to minimize the error relative to a target matrix at the last iteration. The \n",
    "   updating scheme is the following\n",
    "```julia\n",
    "function heat_kernel(X::Array{Float64,2})\n",
    "  Y = copy(X)\n",
    "  Y[2:end-1,2:end-1] .= 0.\n",
    "  Y[2:end-1,2:end-1] = 4. .* X[2:end-1,2:end-1] -  \n",
    "                             X[1:end-2,2:end-1] -\n",
    "                             X[3:end  ,2:end-1] -\n",
    "                             X[2:end-1,1:end-2] -\n",
    "                             X[2:end-1,3:end]\n",
    "  return Y\n",
    "```\n",
    "For better explanation, we furnish a Julia sequential version of the problem in the file `heat_seq.jl`\n",
    "Numericians often call that a 4-stencil. Each interior point of the matrix is computed used its values\n",
    "and its 4 neighbour values. We could sum up with the following picture\n",
    "\n",
    "<figure>\n",
    "<img src=\"figures/buffer.svg\" width=\"300\" alt=\"4-stencil schema\"/>\n",
    "<figcaption> matrix updating scheme\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "In the contrary of the previous problem, all the parallel part is done at the lower level. The Julia\n",
    "program will not \"see\" the partitioned matrix U. the Julia program interacts with the Fortran code,\n",
    "proposing a vector $p$ for the value of the boundary $\\Gamma$ and the fortran program could return\n",
    "the value of the function or the gradient : we use the `optional` feature of Fortran arguments, and\n",
    "interoperability with C enable us to give null pointer when the argument is not present.\n",
    " \n",
    "### Adjoint method\n",
    "\n",
    "Adjoint method are useful, when we have a state equation, for instance, $F(x,p) = 0$ and we want\n",
    "minimize a function $g(x,p)$ relatively to $p$. Explaining briefly the adjoint method, is not easy,\n",
    "and we recommend to read the two great notes of S. G Johnson about that :\n",
    "\n",
    "- [general](https://github.com/mitmath/18335/blob/master/notes/adjoint/adjoint.pdf) \n",
    "- [recurrence](https://github.com/mitmath/18335/blob/master/notes/adjoint/recurrence2.pdf)\n",
    "\n",
    "In our case, since we have a reccurence, the second note is particularly indicated. To sum up, to\n",
    "compute a gradient of $g(p)= \\| U^n(p) - U^{target} \\|^2$, we need to apply a direct recursion computing\n",
    "the final state and final error, and after we backwardly compute contribution to the gradient using \n",
    "adjoint state. We could another time, take the algorithm from `heat_seq.jl` to understand the principle\n",
    "```julia\n",
    "function simu(p::Array{Float64,1}, compute_gradient::Bool = true)\n",
    " u_f = U_final(p, T) # direct recursion\n",
    " v = sum((u_f - vec(target)).^2)\n",
    " λ = 2 .*(u_f - vec(target))\n",
    " if (!compute_gradient) \n",
    "     return v, λ\n",
    " end\n",
    " F, u, dt = get_F(P)\n",
    " # p-partial derivative ≈ zeroing u in F\n",
    " fₚ = ∂ₚF(n) \n",
    " ∇f = zeros(P)\n",
    " for t=T:-dt:dt\n",
    "     ∇f += fₚ'*λ\n",
    "     λ = ∂ᵤF(λ) # adjoint update ≈ zeroing p in F\n",
    " end\n",
    " return v,  ∇f \n",
    "end\n",
    "``` \n",
    "Some software tools using *automatic differientation* exist to generate a program computing the gradient.\n",
    "For instance, if your code is written in Julia (which is not the purpose of this poster), you could use\n",
    "[JuliaDiff](https://www.juliadiff.org/). For C or Fortran codes, for instance your could use [adifor](https://www.mcs.anl.gov/research/projects/adifor/) or \n",
    "[tapenade](http://tapenade.inria.fr:8080/tapenade/index.jsp). In our case, computing analytical for\n",
    "the adjoint is very simple. Since $F$ is linear, partial differential of $F$ relative to $U$ and $p$,\n",
    "is $F$ herself, zeroing the other component.\n",
    "$$ \\partial_uF(u,p)[v] =  v - \\frac{\\delta t}{h^2} \\cdot K2D(v,0) $$\n",
    "and\n",
    "$$ \\partial_pF(u,p)[q] =  - \\frac{\\delta t}{h^2} \\cdot K2D(0,q) $$\n",
    "One could remark that the two operators are very sparse relative to the entry, which finally\n",
    "remains at a linear cost in matrix size for evaluating these operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added procs [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "      From worker 6:\tf(x_0) = 82.33239977605012     , |∇f(x_0)| = 27.536946871435603\n",
      "      From worker 6:\tf(x_m) = 2.9120417214078144e-8 , |∇f(x_m)| = 2.0709006601629806e-7\n"
     ]
    }
   ],
   "source": [
    "cd(\"../heat\");include(\"cluster_optim.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "### future works\n",
    "- benchmarks must be done : to be sure at least that Fortran parallel code beats Julia sequentiel :-)\n",
    "- the author wants write a package such as MPI.jl but for [OpenCoarrays](https://github.com/sourceryinstitute/opencoarrays). MPI is good for parallelism, but it remains a library for Fortran. Coarrays are part of the standard and are more natural to write parallel algorithms\n",
    "### contact \n",
    " If you have any questions or remarks, please do not hesitate to contact me : marc.fuentes@inria.fr\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0-beta1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
