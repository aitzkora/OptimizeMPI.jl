{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling a parallel simulation code from Julia\n",
    "### About me\n",
    "Marc Fuentes, I'm working on simulation software quality at INRIA (French National Institute for Research in Digital Science and Technology) as a research Engineer. Code is available at [Github](http://github.com/aitzkora/OptimizeMPI.jl)\n",
    "\n",
    "### Rationale\n",
    " \n",
    "We want to do a parameter optimization for a physical process simulated by a parallel software\n",
    "written in Fortran or C. Thus, implementing a robust optimization method in a low-level language \n",
    "could be a waste of time, particularly when you are doing a Ph.D for instance. The aim of this poster\n",
    "is to share some recipes (technical and numerical), to achieve that in Julia. The knowledge level \n",
    "remains deliberately basic, so it can be seen as a tutorial. Our hypotheses are the following : \n",
    "- distributed memory paradigm for parallelism (i.e. MPI) \n",
    "- direct problem is Fortran or C.\n",
    "- possibly, implementing a gradient computation will is done in the low level language.\n",
    "- we focus on continuous optimization (using `Optim.jl`), but principle is the same using JuMP for combinatorial optimization \n",
    "As technical points, we want to explain briefly how to call a piece of external code and how to run \n",
    "Julia scripts in a MPI environment \n",
    "\n",
    "### calling Fortran or C code\n",
    "\n",
    "To call a external piece of code, we use the *Julia* statement `ccall`. As documented\n",
    "[here](https://docs.julialang.org/en/v1/base/c/) or [there](https://craftofcoding.wordpress.com/2017/02/08/calling-c-from-julia-i-simple-arrays/), the syntax is the following\n",
    "```julia\n",
    "ccall((:funcName, library), returnType, (argType1, argType2, ...), (argVal1, argVal2, ...))\n",
    "```\n",
    "where `function_name` is the mangled name of the C function in the shared library library. If you do not know\n",
    "what is mangling, take a look at [there](https://en.wikipedia.org/wiki/Name_mangling) : Roughly languages like \n",
    "Fortran (due to its case insensitivity) or C++ (in which the same function name could have several \n",
    "different signatures), must encode their function names when they interoperate with C.\n",
    "\n",
    "#### Remarks \n",
    "- `library` is only _formally_ a string : you could use `\"./mylib.so\"`, but not `string(pwd(),\"/mylib.so\")`\n",
    "- to use a library which is not in `.`, add the path to `LD_LIBRARY_PATH` before launching \n",
    "**Julia** (Just tested on Linux, adapt the rule for MacOS with `DYLD_LIBRARY_PATH`)\n",
    "- using `dlopen` and `dlsym` one could directly use the function pointer call\n",
    "\n",
    "To start, the following C function `int addTwo(int x) { return x+2; }` could be call\n",
    "```julia\n",
    "run(`gcc -o addTwo.so --shared addTwo.c`);\n",
    "w = ccall((:addTwo, \"./addTwo.so\"), Int32, (Int32,), 12); println(\"$w\")\n",
    "```\n",
    "\n",
    "This example deserves some explanations: \n",
    "1. to build a *shared* library we add on the gcc compiler command the flag `--shared`. This is evidently,\n",
    "compiler dependant. If you use Intel, NAG or Microsoft, it could be different. To enforce more portability,\n",
    "in provided codes, we use **CMake** as an utility to generate Makefiles and doing the compilation. To\n",
    "do that, with CMake, one could write `add_library(name_lib SHARED name_src)`\n",
    "\n",
    "2. One big difference between Fortran and C, is the default argument pass method ; In C, it is by-value,\n",
    "so a function like `addTwo` cannot modify its arguments. To do that, you need to use pointers and furnish\n",
    "a Julia **reference** to `ccall`\n",
    "\n",
    "3. In Fortran, since args are passed by reference, we will use a reference.\n",
    "\n",
    "```fortran\n",
    "module example\n",
    "  use iso_c_binding\n",
    "contains\n",
    "  subroutine addTwoF(x) bind(C, name =\"addTwoF\")\n",
    "    integer(c_int), intent (inout) :: x\n",
    "    x = x + 2\n",
    "  end subroutine \n",
    "end module\n",
    "```\n",
    "\n",
    "In this example, we used the statement bind to attach a C name to our Fortran function. It will override\n",
    "the mangled name, when we will use `ccall`. To enforce compatibility, Fortran 90 has some \n",
    "C compatibles types , such as  `real(c_double)`, `integer(c_int)` defined in the module `iso_c_binding`.\n",
    "The `intent(inout)` does not change how the argument is passed (by reference), it is just a information\n",
    "to enable the compiler to do more checks.\n",
    "\n",
    "```julia\n",
    "z = Ref{Int32}(12) # ✏️ VERY IMPORTANT ✏️\n",
    "w = ccall((:addTwoF, \"./addTwoF.so\"), Cvoid, (Ref{Int32},), z)\n",
    "println(\"z = \",z[])\n",
    "```\n",
    "\n",
    "4. To end with external code calling, we have to speak about arrays : Julia arrays can be convert \n",
    "to pointers without any problem, when using `ccall` As an example, `void changeArray(int n, double * x) { if (n > 1) x[0] += 3 ; }` could be call by\n",
    "\n",
    "```julia\n",
    "a = [1:3.;]; ccall((:changeArray, \"./changeArray.so\"), Cvoid,(Int32, Ptr{Float64},), size(a,1), a) println(\"$a\")\n",
    "```\n",
    "\n",
    "### Interacting with MPI\n",
    "\n",
    "Interacting with MPI, is not so hard, thanks to the good job done by authors of `MPI.jl` and \n",
    "`MPIClusterManagers` packages.a For instance, using `MPI.jl`, one could run \n",
    "```julia\n",
    "using MPI\n",
    "MPI.Init()\n",
    "println(\"Hi from $(MPI.Comm_rank(MPI.COMM_WORLD))!\")\n",
    "flush(stdout)\n",
    "```\n",
    "directly from shell `mpirun -np 2 julia examples/hello_world.jl`.\n",
    "\n",
    "Doing so, since `mpirun` calls julia, the julia code, is JIT-compiled before to execute each time we run \n",
    "the script; Furthermore, we must run the code out of the Julia REPL, which is not very  convenient for \n",
    "doing some experiments. To avoid that, we can use the `MPIClusterManagers` package's macro `@mpi_do` after\n",
    "the following preamble\n",
    "```julia\n",
    "using MPIClusterManagers, Distributed\n",
    "manager = MPIManager(np=4)\n",
    "addprocs(manager)\n",
    "@everywhere import MPI\n",
    "```\n",
    "and running several times the following block without restarting Julia\n",
    "```julia\n",
    "@mpi_do manager begin \n",
    "    comm = MPI.COMM_WORLD;p = MPI.Comm_size(comm);r = MPI.Comm_rank(comm)\n",
    "    s_loc=sum(1+r* 100/p:100/p * (r+1)); s=MPI.Allreduce(s_loc, +, comm)\n",
    "    println(\"s=$s\")\n",
    "end\n",
    "```\n",
    "Unfortunately, the present version of MPIClusterManagers does not have an `@mpi_fetchcall` macro\n",
    "to retrieve the result of the computation on the master (which is not part of the MPI Cluster).\n",
    "\n",
    "### Distributed Minimization\n",
    "\n",
    "#### preliminary remark\n",
    "Formally, we want to solve a problem like\n",
    "$$ \\min_{x_1,\\cdots,x_p} f(x_1,\\cdots,x_p) \\mbox { where } x_i \\in \\mathbb{R}^{n_i}$$\n",
    "the main function $f$ is assumed decomposable, i.e, we could write as a max or a sum of functions defined\n",
    "on each  $\\mathbb{R}^{n_i}$, for instance\n",
    "$$ f(x_1,\\cdots,x_p) = \\sum_{i=1}^p f_i(x_i)$$\n",
    "In almost all optimization methods, you have a **linesearch** step, which try to find the step length \n",
    "$\\alpha$ to go forward in the descent direction. Since the computation is distributed, each algorithm, \n",
    "owns a version of the current step. Fortunately, since the **linesearch** uses only the value of\n",
    "the function, which it is the same on each process, so $\\alpha$ must be the same across processes.\n",
    "\n",
    "#### A dummy example : the squared $L_2$ norm\n",
    "Suppose we want to minimize  $f(x) = \\frac{1}{2}\\|x-c\\|^2$ where $c$ is a constant vector. The solution\n",
    "is trivially equal to $c$. We also remark that if we cut $\\mathbb{R}^n$ into some chunks, \n",
    "the $f$ function is clearly decomposable and each $f_i$ is just $f_i(x_i) = \\frac{1}{2}\\|x_i - c_i\\|^2$ where\n",
    "$c_i$ has the chunk components of $c$. Even if this case, we do not need a gradient to find the solution,\n",
    "one can computes very easily seeing that\n",
    "$$\\nabla f(x) = \\bigoplus_{i=1}^p \\nabla f_i(x_i) = \\bigoplus_{i=1}^p (x_i - c_i) $$.\n",
    "Since this example is very dumb, we directly build the partition of state vector  $x$ in Julia and computing\n",
    "$f_i,\\nabla f_i$ is coded in Fortran. To partitionate $x$ we computes the chunk sizes according to\n",
    "\n",
    "```julia\n",
    "function partition(n::Integer, p::Integer)\n",
    " r = n % p\n",
    " m = ceil(Integer, n / p)\n",
    " part = fill( m, p )\n",
    " part[ (r+1) * (r> 0) + (p+1) * (r==0): p ] .= m - 1\n",
    " return part\n",
    "end\n",
    "```\n",
    "Then, Julia gather the chunks on the root process\n",
    "```julia\n",
    "x_glob = MPI.Gatherv(x_min,Cint[i for i in partition(n,p)] , 0, comm)\n",
    "```\n",
    "The low-level part, is simply a computation of the local squared norm and with `MPI_ALLREDUCE`\n",
    "we shared the global sum among all processes. \n",
    "```fortran\n",
    "subroutine compute_error(n, x, c, f, df) bind(C, name=\"compute_error\")\n",
    "(...)\n",
    "  f = 0.d0\n",
    "  ! computing objective\n",
    "  f_loc = 0.5d0 * sum( (x - c)**2 )\n",
    "  call MPI_ALLREDUCE( f_loc, f, 1, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD, ierr )\n",
    "  ! computing gradient\n",
    "  df = x - c\n",
    "end subroutine compute_error\n",
    "```\n",
    "Now, we it remains to write the interface using `ccall`\n",
    "```julia\n",
    "function simu!(n::Integer, x::Array{Float64,1}, df::Array{Float64,1})\n",
    "  f = Ref{Float64}(0.)\n",
    "  c = cos.(1:n)[slice[1]:slice[2]]\n",
    "  ccall((:compute_error, \"./libpar_error.so\"), \n",
    "  Cvoid, (Ref{Int32}, Ptr{Float64}, Ptr{Float64}, Ref{Float64}, Ptr{Float64}), size(x, 1), x, c, f, df)\n",
    "  return f[]\n",
    "end\n",
    "```\n",
    "For simplicity, we choose $c_i = \\cos(i)$ and the slices are shared as a global variable (very bad!)\n",
    "\n",
    "We can now choose our favorite minimization algorithm : Most of people likes Nelder-Mead algorithm\n",
    "because it does not require gradient, but please do not use it,  proofs of convergence towards\n",
    "non-stationary points exist in the literature [Torczon](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.48.9967) \n",
    " or [McKinnon](https://www.researchgate.net/publication/2763859_Convergence_of_the_Nelder-Mead_simplex_method_to_a_non-stationary_point). Since we have a gradient at our disposal, why not choose a \"1.5\" order \n",
    "method like `LBFGS` ?\n",
    " ```julia\n",
    "res = optimize(cost, grad!, x_loc, LBFGS(), Optim.Options(... ))\n",
    " ```\n",
    "where `cost` and `grad!` are defined by  `cost = x -> simu!(n, x, df_dummy)` and  `grad! = (g,x)-> simu!(n,x,g)`\n",
    "\n",
    "Note, doing that is costly, because we compute a gradient even if we just need $f$. We will see, in the\n",
    "next example that we must be able to compute $f$ without computing $\\nabla f$.\n",
    "\n",
    "#### A more advance example : controlling the 2D heat equation\n",
    "\n",
    "We will now consider a more realistic problem : it remains a toy problem (just 1600 loc), but to solve\n",
    "it, we will need of a classical tool for time dependent problems : the adjoint method.\n",
    "Before to explain this point, let us describe the problem\n",
    "\n",
    "We will heat a square, just applying from the beginning to the end of the simulation the same values \n",
    "on the boundary $\\Gamma$ of the square. It is our control ; we want obtain for $t=t_{final}$ some values inside \n",
    "the square as close as possible to a target function. \n",
    "In a continuous world, we want to solve\n",
    "\\begin{eqnarray}\n",
    "   \\min_p && \\int_{[0,1]^2} (u(x,t_{final}) - u_{target}(x))^2 \\, dx \\\\\n",
    "   \\mbox { such that }     && \\frac{\\partial u}{\\partial t} (x,t) = \\Delta u(x,t) \\forall (x,t) \\in [0,1]^2 \\times [0,t_{final}] \\\\ \n",
    "    && u(x,t) = p(x)  \\forall  (x,t) \\in \\Gamma \\times [0,t_{final}]\n",
    "\\end{eqnarray}\n",
    "\n",
    "We discretize this system, using finite differente scheme for space and Euler formula for time, and obtain\n",
    "\\begin{eqnarray}\n",
    "   \\min_p &&  \\|U^n- U^{target}\\|^2_{inside}  \\\\\n",
    "   \\mbox { such that }     && U^{n+1} = F(U^n,p) = U^n - \\frac{\\delta t}{h^2} \\cdot K2D(U^n,p) \\\\\n",
    "                           && U^0 = 0. \n",
    "\\end{eqnarray}\n",
    "\n",
    "where $K2D$ is the heat kernel with $p$ on the boundary. For those who do not like these formulae,\n",
    "just remember that we have a recursive sequence of matrices, and controlling boundary matrix \n",
    "terms, we want to minimize the error relative to a target matrix at the last iteration. The \n",
    "updating scheme is the following\n",
    "\n",
    "![update scheme](figures/buffer.pdf)\n",
    "\n",
    "For better explanation, we furnish a Julia sequential version of the problem in the file `heat_seq.jl`\n",
    "Numericians often call that a 4-stencil. Each interior point of the matrix is computed used its values\n",
    "and its 4 neighbour values. In the contrary of the previous problem, all the parallel part is done \n",
    "in Fortran. The Julia program interacts with the Fortran code, proposing a vector $p$ for the value of the boundary $\\Gamma$ and the fortran program could return the value of the function or the gradient : we use \n",
    "the `optional` feature of Fortran arguments, and interoperability with C enable us to give null pointer when the argument is not present.\n",
    " \n",
    "##### Adjoint method\n",
    "\n",
    "Adjoint method are useful, when we have a state equation, for instance, $F(x,p) = 0$ and we want\n",
    "minimize a function $g(x,p)$ relatively to $p$. Explaining briefly the adjoint method, is not easy,\n",
    "and we recommend to read the [note of about reccurence](https://github.com/mitmath/18335/blob/master/notes/adjoint/recurrence2.pdf) S. G Johnson. To sum up, to compute a gradient of $g(p)= \\| U^n(p) - U^{target} \\|^2$, \n",
    "we need to apply a direct recursion computing the final state and final error, and after we \n",
    "backwardly compute contribution to the gradient using adjoint state. We could another time, take \n",
    "the algorithm from `heat_seq.jl` to understand the principle\n",
    "```julia\n",
    "function simu(p::Array{Float64,1}, compute_gradient::Bool = true)\n",
    " u_f = U_final(p, T) # direct recursion\n",
    " v = sum((u_f - vec(target)).^2)\n",
    " λ = 2 .*(u_f - vec(target))\n",
    " (...) \n",
    " fₚ = ∂ₚF(n) # p-partial derivative ≈ zeroing u in F \n",
    " ∇f = zeros(P)\n",
    " for t=T:-dt:dt\n",
    "     ∇f += fₚ'*λ\n",
    "     λ = ∂ᵤF(λ) # adjoint update ≈ zeroing p in F\n",
    " end\n",
    " return v,  ∇f \n",
    "end\n",
    "``` \n",
    "Some software tools using *automatic differentiation* exist to generate a program computing the gradient.\n",
    "For instance, if your code is written in Julia (which is not the purpose of this poster), you could use\n",
    "[JuliaDiff](https://www.juliadiff.org/). For C or Fortran codes, for instance your could use [adifor](https://www.mcs.anl.gov/research/projects/adifor/) or \n",
    "[tapenade](http://tapenade.inria.fr:8080/tapenade/index.jsp). In our case, computing analytical for\n",
    "the adjoint is very simple. Since $F$ is linear, partial differential of $F$ relative to $U$ and $p$,\n",
    "is $F$ herself, zeroing the other component.\n",
    "$$ \\partial_uF(u,p)[v] =  v - \\frac{\\delta t}{h^2} \\cdot K2D(v,0) \\mbox{ and }\n",
    "\\partial_pF(u,p)[q] =  - \\frac{\\delta t}{h^2} \\cdot K2D(0,q) $$\n",
    "One could remark that the two operators are very sparse, which is good for us\n",
    "\n",
    "#### Future works\n",
    "- In the heat problem, after computing the optimal $p$, we could compute at least the final U.\n",
    "- benchmarks must be done : to be sure that Fortran parallel code beats Julia sequentiel\n",
    "- the author wants to write a package in the same spirit as MPI.jl but  for [OpenCoarrays](https://github.com/sourceryinstitute/opencoarrays). MPI is well suited for  parallelism, but it remains a library in Fortran. Coarrays are now part of the standard and they are  more natural to write parallel algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0-beta1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
